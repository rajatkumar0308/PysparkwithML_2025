{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfc8bbc2-e6e4-48a9-a4c2-5b75e898e986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Problem Statement\n",
    "#A bank wants to predict whether a customer will repay a loan. They have the following customer details:\n",
    "\n",
    "#Age: Age of the customer.\n",
    "#Monthly_Income: Monthly income of the customer.\n",
    "#Loan_Amount: Total loan amount requested.\n",
    "#Credit_Score: A score indicating creditworthiness (0â€“1000).\n",
    "#Employment_Years: Number of years the customer has been employed.\n",
    "#The target variable is: Loan_Default (Yes/No): Whether the customer defaults on the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c19a7961-a88c-466e-8fc1-7065e18b01e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-----------+------------+----------------+------------+\n|Age|Monthly_Income|Loan_Amount|Credit_Score|Employment_Years|Loan_Default|\n+---+--------------+-----------+------------+----------------+------------+\n| 58|         12485|       5037|         555|              28|          No|\n| 25|         13274|      44252|         377|              34|         Yes|\n| 19|         11125|      26243|         753|              19|         Yes|\n| 65|          5598|      37021|         863|              39|          No|\n| 35|         13216|       6276|         400|              33|         Yes|\n| 33|          7313|      12331|         351|               0|          No|\n| 32|         14588|      28788|         967|              35|         Yes|\n| 26|         14713|      25153|         853|              19|         Yes|\n| 65|          2916|      20692|         315|               6|          No|\n| 24|          5752|       8796|         395|               8|          No|\n| 61|          2525|      20785|         542|              16|          No|\n| 65|          7168|      42182|         470|               7|          No|\n| 52|          8572|      10161|         716|               6|         Yes|\n| 23|          6386|      10613|         797|              35|          No|\n| 55|          3084|      36849|         792|               9|         Yes|\n| 45|          5456|       9535|         518|              17|          No|\n| 20|         11292|      39911|         710|              18|         Yes|\n| 19|         13762|      13241|         360|              38|          No|\n| 23|          7155|      13414|         468|              13|         Yes|\n| 31|          5483|      48237|         688|              21|         Yes|\n+---+--------------+-----------+------------+----------------+------------+\nonly showing top 20 rows\n\nroot\n |-- Age: double (nullable = true)\n |-- Monthly_Income: double (nullable = true)\n |-- Loan_Amount: double (nullable = true)\n |-- Credit_Score: double (nullable = true)\n |-- Employment_Years: double (nullable = true)\n |-- Loan_Default: string (nullable = true)\n |-- label: double (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer   #Most machine learning algorithms (including Decision Trees and Random Forests) cannot directly handle categorical strings like \"Yes\" or \"No\". They work on numeric data, so categorical values must be transformed into numbers.\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Step 1: Load the data into PySpark DataFrame\n",
    "\n",
    "# Assuming the data is loaded into a DataFrame (e.g., from a CSV or database)\n",
    "data_df = spark.sql(\"SELECT * FROM loan_default_data\")\n",
    "data_df.show()\n",
    "# Ensure numeric data types for the features\n",
    "from pyspark.sql.functions import col\n",
    "data_df = data_df.withColumn(\"Age\", col(\"Age\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Monthly_Income\", col(\"Monthly_Income\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Loan_Amount\", col(\"Loan_Amount\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Credit_Score\", col(\"Credit_Score\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Employment_Years\", col(\"Employment_Years\").cast(\"double\"))\n",
    "\n",
    "# Convert the target variable to numeric using StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"Loan_Default\", outputCol=\"label\")\n",
    "data_df = indexer.fit(data_df).transform(data_df)\n",
    "\n",
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03f67fb7-e4ae-4865-8734-075069787bb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----------+------------+----------------+------------+-----+\n| Age|Monthly_Income|Loan_Amount|Credit_Score|Employment_Years|Loan_Default|label|\n+----+--------------+-----------+------------+----------------+------------+-----+\n|58.0|       12485.0|     5037.0|       555.0|            28.0|          No|  0.0|\n|25.0|       13274.0|    44252.0|       377.0|            34.0|         Yes|  1.0|\n|19.0|       11125.0|    26243.0|       753.0|            19.0|         Yes|  1.0|\n|65.0|        5598.0|    37021.0|       863.0|            39.0|          No|  0.0|\n|35.0|       13216.0|     6276.0|       400.0|            33.0|         Yes|  1.0|\n|33.0|        7313.0|    12331.0|       351.0|             0.0|          No|  0.0|\n|32.0|       14588.0|    28788.0|       967.0|            35.0|         Yes|  1.0|\n|26.0|       14713.0|    25153.0|       853.0|            19.0|         Yes|  1.0|\n|65.0|        2916.0|    20692.0|       315.0|             6.0|          No|  0.0|\n|24.0|        5752.0|     8796.0|       395.0|             8.0|          No|  0.0|\n|61.0|        2525.0|    20785.0|       542.0|            16.0|          No|  0.0|\n|65.0|        7168.0|    42182.0|       470.0|             7.0|          No|  0.0|\n|52.0|        8572.0|    10161.0|       716.0|             6.0|         Yes|  1.0|\n|23.0|        6386.0|    10613.0|       797.0|            35.0|          No|  0.0|\n|55.0|        3084.0|    36849.0|       792.0|             9.0|         Yes|  1.0|\n|45.0|        5456.0|     9535.0|       518.0|            17.0|          No|  0.0|\n|20.0|       11292.0|    39911.0|       710.0|            18.0|         Yes|  1.0|\n|19.0|       13762.0|    13241.0|       360.0|            38.0|          No|  0.0|\n|23.0|        7155.0|    13414.0|       468.0|            13.0|         Yes|  1.0|\n|31.0|        5483.0|    48237.0|       688.0|            21.0|         Yes|  1.0|\n+----+--------------+-----------+------------+----------------+------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Prepare the data\n",
    "feature_columns = [\"Age\", \"Monthly_Income\", \"Loan_Amount\", \"Credit_Score\", \"Employment_Years\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data_prepared = assembler.transform(data_df).select(\"features\", \"label\")\n",
    "data_df.show()\n",
    "\n",
    "# Step 3: Split the data into training and test sets\n",
    "train_data, test_data = data_prepared.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4eeef59-b773-4ddb-8c61-bb053d08ea58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model:\n  Depth: 5\n  Number of Nodes: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4a: Train the Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# Output Decision Tree model details\n",
    "print(\"Decision Tree Model:\")\n",
    "print(f\"  Depth: {dt_model.depth}\")\n",
    "print(f\"  Number of Nodes: {dt_model.numNodes}\")\n",
    "\n",
    "# print(f\"  Depth: {dt_model.depth}\") Purpose: Prints the depth of the trained Decision Tree model.\n",
    "#What is Depth?\n",
    "#The depth of a decision tree is the number of levels in the tree.\n",
    "#The root node is at depth 0, and the maximum depth of the tree is the length of the longest path from the root to a leaf node.\n",
    "#A deeper tree can model more complex patterns but is also more prone to overfitting.\n",
    "\n",
    "#print(f\"  Number of Nodes: {dt_model.numNodes}\") Purpose: Prints the total number of nodes in the trained Decision Tree model.\n",
    "#What are Nodes?\n",
    "#Nodes in a decision tree represent decision points based on feature values.\n",
    "#Includes:\n",
    "#Decision nodes: Where the model makes a split.\n",
    "#Leaf nodes: Terminal nodes where predictions are made.\n",
    "#Implication:\n",
    "#More nodes generally indicate a more complex tree.\n",
    "#A large number of nodes can increase model complexity and risk of overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95ff68c5-64ee-45fe-8a68-3a08668faf56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model:\n  Number of Trees: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4b: Train the Random Forest Classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Output Random Forest model details\n",
    "print(\"Random Forest Model:\")\n",
    "print(f\"  Number of Trees: {rf_model.getNumTrees}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2dc216a-06d3-45e7-9c7e-b0e2ea99deb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n|            features|label|prediction|\n+--------------------+-----+----------+\n|[19.0,12532.0,223...|  0.0|       0.0|\n|[20.0,14302.0,359...|  0.0|       1.0|\n|[22.0,12468.0,121...|  1.0|       1.0|\n|[23.0,9668.0,3869...|  1.0|       1.0|\n|[25.0,13274.0,442...|  1.0|       0.0|\n|[28.0,5258.0,1746...|  0.0|       1.0|\n|[31.0,10085.0,271...|  1.0|       1.0|\n|[32.0,14592.0,359...|  0.0|       1.0|\n|[36.0,6119.0,2325...|  1.0|       0.0|\n|[36.0,12501.0,316...|  1.0|       1.0|\n|[39.0,3489.0,6378...|  0.0|       1.0|\n|[40.0,4621.0,5471...|  0.0|       1.0|\n|[40.0,12280.0,194...|  1.0|       1.0|\n|[42.0,3796.0,2008...|  0.0|       0.0|\n|[46.0,6304.0,4901...|  1.0|       1.0|\n|[52.0,8572.0,1016...|  1.0|       1.0|\n|[56.0,10317.0,212...|  0.0|       1.0|\n+--------------------+-----+----------+\n\n+--------------------+-----+----------+\n|            features|label|prediction|\n+--------------------+-----+----------+\n|[19.0,12532.0,223...|  0.0|       0.0|\n|[20.0,14302.0,359...|  0.0|       1.0|\n|[22.0,12468.0,121...|  1.0|       1.0|\n|[23.0,9668.0,3869...|  1.0|       1.0|\n|[25.0,13274.0,442...|  1.0|       1.0|\n|[28.0,5258.0,1746...|  0.0|       1.0|\n|[31.0,10085.0,271...|  1.0|       0.0|\n|[32.0,14592.0,359...|  0.0|       1.0|\n|[36.0,6119.0,2325...|  1.0|       1.0|\n|[36.0,12501.0,316...|  1.0|       1.0|\n|[39.0,3489.0,6378...|  0.0|       1.0|\n|[40.0,4621.0,5471...|  0.0|       0.0|\n|[40.0,12280.0,194...|  1.0|       0.0|\n|[42.0,3796.0,2008...|  0.0|       0.0|\n|[46.0,6304.0,4901...|  1.0|       1.0|\n|[52.0,8572.0,1016...|  1.0|       1.0|\n|[56.0,10317.0,212...|  0.0|       1.0|\n+--------------------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Make predictions\n",
    "# Decision Tree predictions\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "dt_predictions.select(\"features\", \"label\", \"prediction\").show()\n",
    "\n",
    "# Random Forest predictions\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "rf_predictions.select(\"features\", \"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "219857d8-f8be-4f1f-a970-eef2ab02290f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Performance:\n  Accuracy: 0.5294117647058824\nRandom Forest Model Performance:\n  Accuracy: 0.5882352941176471\nSummary of Results:\nDecision Tree:\n  Accuracy: 0.5294117647058824\nRandom Forest:\n  Accuracy: 0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Evaluate the models\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "dt_accuracy = evaluator.evaluate(dt_predictions)\n",
    "print(\"Decision Tree Model Performance:\")\n",
    "print(f\"  Accuracy: {dt_accuracy}\")\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
    "print(\"Random Forest Model Performance:\")\n",
    "print(f\"  Accuracy: {rf_accuracy}\")\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "print(\"Summary of Results:\")\n",
    "print(\"Decision Tree:\")\n",
    "print(f\"  Accuracy: {dt_accuracy}\")\n",
    "print(\"Random Forest:\")\n",
    "print(f\"  Accuracy: {rf_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1bfc214-c3bc-495a-a48f-96fd12bbbc2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Decision Tree Model Performance: Achieved an accuracy of 52.94%, indicating correct predictions for roughly half the test dataset.\n",
    "#Random Forest Model Performance: Achieved an accuracy of 58.82%, showing improved prediction reliability due to ensemble learning.\n",
    "#Summary of Results: Random Forest outperformed Decision Tree by approximately 5.88% in accuracy, highlighting the benefits of combining multiple trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af239bc5-e593-435d-9a62-9b8aecb93381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5e10cc9-c4f5-4fce-872f-0d6c983d5451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b428480-b016-4c90-b180-58437d7e4984",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcff9908-3553-4a07-8620-f3610b0971bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f78795f-65d3-41dd-bc1e-d36ed4de1831",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Decision tree",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
