{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd531515-3291-4154-a1c8-a7fbf8999b88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.00\nRandom Forest Accuracy: 1.00\nRandom Forest performs better.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession  # This imports the SparkSession class, the entry point for using Spark.\n",
    "from pyspark.sql.functions import col, when  # Imports functions for column selection and conditional operations.\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer  # Tools for feature engineering: creating feature vectors and indexing categorical data.\n",
    "from pyspark.ml import Pipeline  # Enables building machine learning pipelines in PySpark.\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier  # Machine learning algorithms for classification tasks.\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator  # Evaluates the performance of classification models.\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark ML Pipeline\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.memory\", \"1g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "\n",
    "# Load Dataset (simulated data)\n",
    "data = [\n",
    "    (1, 34, 15000, \"No\"),\n",
    "    (2, 45, 20000, \"Yes\"),\n",
    "    (3, 23, 12000, \"No\"),\n",
    "    (4, 36, 30000, \"No\"),\n",
    "    (5, 52, 8000, \"Yes\"),\n",
    "    (6, 30, 22000, \"No\"),\n",
    "    (7, 40, 10000, \"Yes\"),\n",
    "    (8, 28, 14000, \"No\"),\n",
    "    (9, 35, 25000, \"No\"),\n",
    "    (10, 48, 7000, \"Yes\")\n",
    "]\n",
    "columns = [\"CustomerID\", \"Age\", \"Income\", \"Churn\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)  # Converts the dataset into a Spark DataFrame for processing.\n",
    "\n",
    "# Data Preprocessing\n",
    "# Convert target variable 'Churn' into numerical format\n",
    "indexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label\")  # Converts the 'Churn' column into a numeric label.\n",
    "\n",
    "# Feature engineering\n",
    "feature_cols = [\"Age\", \"Income\"]  # Specifies the columns to be used as features.\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")  # Combines features into a single vector.\n",
    "\n",
    "# Splitting the dataset into training and testing\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)  # Splits data into 80% training and 20% testing.\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")  # Initializes the Logistic Regression model.\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")  # Initializes the Random Forest model.\n",
    "\n",
    "# Build a Pipeline for Logistic Regression\n",
    "lr_pipeline = Pipeline(stages=[indexer, assembler, lr])  # Defines a pipeline with preprocessing and Logistic Regression.\n",
    "#indexer: Encodes the target variable (Churn) into numeric format.\n",
    "#assembler: Combines feature columns (Age and Income) into a single vector.\n",
    "#lr: Trains a logistic regression model using the processed features and labels.\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model = lr_pipeline.fit(train_data)  # Fits the pipeline to the training data.\n",
    "\n",
    "# Evaluate Logistic Regression model\n",
    "if not test_data.isEmpty():  # Ensure test_data is not empty to avoid errors\n",
    "    lr_predictions = lr_model.transform(test_data)  # Generates predictions for the test dataset.\n",
    "    lr_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")  # Evaluates accuracy of predictions.\n",
    "    lr_accuracy = lr_evaluator.evaluate(lr_predictions)  # Calculates accuracy for Logistic Regression.\n",
    "    print(f\"Logistic Regression Accuracy: {lr_accuracy:.2f}\")\n",
    "else:\n",
    "    print(\"Test data is empty. Cannot evaluate Logistic Regression model.\")\n",
    "\n",
    "# Build a Pipeline for Random Forest\n",
    "rf_pipeline = Pipeline(stages=[indexer, assembler, rf])  # Defines a pipeline with preprocessing and Random Forest.\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = rf_pipeline.fit(train_data)  # Fits the pipeline to the training data.\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "if not test_data.isEmpty():  # Ensure test_data is not empty to avoid errors\n",
    "    rf_predictions = rf_model.transform(test_data)  # Generates predictions for the test dataset.\n",
    "    rf_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")  # Evaluates accuracy of predictions.\n",
    "    rf_accuracy = rf_evaluator.evaluate(rf_predictions)  # Calculates accuracy for Random Forest.\n",
    "    print(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")\n",
    "\n",
    "    # Compare Results\n",
    "    if lr_accuracy > rf_accuracy:\n",
    "        print(\"Logistic Regression performs better.\")\n",
    "    else:\n",
    "        print(\"Random Forest performs better.\")\n",
    "else:\n",
    "    print(\"Test data is empty. Cannot evaluate Random Forest model.\")\n",
    "\n",
    "# Save model (optional)\n",
    "rf_model.write().overwrite().save(\"rf_model_path\")  # Saves the trained Random Forest model.\n",
    "lr_model.write().overwrite().save(\"lr_model_path\")  # Saves the trained Logistic Regression model.\n",
    "\n",
    "# Stop Spark session\n",
    "# # Stops the Spark session to release resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab8e2433-0335-4c09-8604-d227fdeeb109",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In summary, Random Forest generally performs better in real-world scenarios due to its ability to capture complex patterns, handle noise, and manage feature interactions. However, the accuracy of 1.00 on the given dataset for both models might indicate that the dataset is simple or that both models have been fine-tuned to the point of overfitting."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bootcamp_PYspark_pipleline_Project",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
