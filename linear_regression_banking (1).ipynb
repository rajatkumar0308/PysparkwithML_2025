{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aab5c73d-04d8-4820-a1c0-44d33d7f75e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+---------------+-----------+----------------------+------------------+--------------+--------------------+\n|Customer_ID|Age|Account_Balance|Loan_Amount|Loan_Approval_Duration|     Interest_Rate|Monthly_Income| Default_Probability|\n+-----------+---+---------------+-----------+----------------------+------------------+--------------+--------------------+\n|          1| 58|          90135|      47217|                    20| 9.089529444142698|          6491|0.026366974497252005|\n|          2| 48|          36222|      22056|                     8|6.7329432007084575|         13130|  0.3764633668780496|\n|          3| 34|          78373|      39059|                     7| 6.564370426710861|          9651|  0.8105533307818329|\n|          4| 27|          80575|      26809|                     3| 7.502428981645953|          3167|  0.9872761293149445|\n|          5| 40|          97354|      22419|                    17|10.492266647061204|          3062| 0.15041689110352818|\n|          6| 58|          85651|       5431|                    33|12.145959227000624|         13174|  0.5941307153521351|\n|          7| 38|          64335|      33470|                    12|11.601973767177313|          6729|  0.3808908566310215|\n|          8| 42|          11965|      44715|                    22| 7.799338969459429|         11348|  0.9699143978146032|\n|          9| 30|          25538|      13188|                    22| 14.54865280663194|          7334|  0.8421189231357087|\n|         10| 30|          71592|      25842|                    30|12.378969166957685|         10924|  0.8383287047111379|\n|         11| 43|          99018|      37657|                     8|10.543540525114008|          6330|  0.4686931597949703|\n|         12| 55|           9110|       2827|                    27|11.117207462343522|          8801|  0.4148195023376652|\n|         13| 59|          80309|      41272|                    27|   9.1960006242779|          6846| 0.27340707193070624|\n|         14| 43|          28266|      41045|                    34| 7.477309895011574|          8731|0.056375496650927115|\n|         15| 22|          53992|        697|                    21| 8.559726786512616|         17368|  0.8647223762550532|\n|         16| 41|          83948|      24009|                    30| 12.57846110464369|         19337|  0.8129010091300776|\n|         17| 21|          99806|      35198|                    33| 5.143934886297559|          4539|  0.9997176732861306|\n|         18| 43|           7910|      45042|                    28| 6.160726405069163|          9056|  0.9966368370739054|\n|         19| 49|          91982|      15587|                    33|5.4600264202175275|         13516|  0.5554317056026274|\n|         20| 57|           1206|      23171|                     5| 5.407288023189701|         13493|  0.7689874151805105|\n+-----------+---+---------------+-----------+----------------------+------------------+--------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Databricks notebook: Linear Regression with PySpark\n",
    "\n",
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession  # Create and manage a Spark session.\n",
    "from pyspark.ml.feature import VectorAssembler  # Combine features into a single vector for ML.\n",
    "from pyspark.ml.regression import LinearRegression  # Train and apply linear regression models.\n",
    "from pyspark.ml.evaluation import RegressionEvaluator  # Evaluate regression model performance.\n",
    "\n",
    "# Step 1: Load the CSV file into PySpark DataFrame\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"LinearRegression-Bank\").getOrCreate()  # Start a new Spark session.\n",
    "\n",
    "data_df = spark.sql(\"SELECT * FROM bank_data\")\n",
    "# Display the first few rows of the DataFrame to verify loading\n",
    "data_df.show()  # View the loaded data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d45fd55e-8142-4d00-a593-7b4c0f29cd2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Customer_ID: string (nullable = true)\n |-- Age: double (nullable = true)\n |-- Account_Balance: double (nullable = true)\n |-- Loan_Amount: double (nullable = true)\n |-- Loan_Approval_Duration: string (nullable = true)\n |-- Interest_Rate: double (nullable = true)\n |-- Monthly_Income: double (nullable = true)\n |-- Default_Probability: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#PySpark's VectorAssembler requires numeric data types to process features.\n",
    "# You need to ensure the columns in the DataFrame have numeric data types before passing them to the VectorAssembler.\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "data_df = data_df.withColumn(\"Age\", col(\"Age\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Account_Balance\", col(\"Account_Balance\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Loan_Amount\", col(\"Loan_Amount\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Interest_Rate\", col(\"Interest_Rate\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Monthly_Income\", col(\"Monthly_Income\").cast(\"double\")) \\\n",
    "                 .withColumn(\"Default_Probability\", col(\"Default_Probability\").cast(\"double\"))\n",
    "\n",
    "data_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28e618c4-4690-4318-bb34-130e530fd119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n|            features| Default_Probability|\n+--------------------+--------------------+\n|[58.0,90135.0,472...|0.026366974497252005|\n|[48.0,36222.0,220...|  0.3764633668780496|\n|[34.0,78373.0,390...|  0.8105533307818329|\n|[27.0,80575.0,268...|  0.9872761293149445|\n|[40.0,97354.0,224...| 0.15041689110352818|\n|[58.0,85651.0,543...|  0.5941307153521351|\n|[38.0,64335.0,334...|  0.3808908566310215|\n|[42.0,11965.0,447...|  0.9699143978146032|\n|[30.0,25538.0,131...|  0.8421189231357087|\n|[30.0,71592.0,258...|  0.8383287047111379|\n|[43.0,99018.0,376...|  0.4686931597949703|\n|[55.0,9110.0,2827...|  0.4148195023376652|\n|[59.0,80309.0,412...| 0.27340707193070624|\n|[43.0,28266.0,410...|0.056375496650927115|\n|[22.0,53992.0,697...|  0.8647223762550532|\n|[41.0,83948.0,240...|  0.8129010091300776|\n|[21.0,99806.0,351...|  0.9997176732861306|\n|[43.0,7910.0,4504...|  0.9966368370739054|\n|[49.0,91982.0,155...|  0.5554317056026274|\n|[57.0,1206.0,2317...|  0.7689874151805105|\n+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 2: Prepare the data\n",
    "# Select relevant features for the model  \n",
    "feature_columns = [\"Age\", \"Account_Balance\", \"Loan_Amount\", \"Interest_Rate\", \"Monthly_Income\"]  # selected Features for the model.\n",
    "\n",
    "# Combine selected features into a single vector column (Optimized Performance,Compatibility with ML Algorithms,Scalability)\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")  # Create a feature vector , VectorAssembler transforms raw data into this required format .\n",
    "data_prepared = assembler.transform(data_df).select(\"features\", \"Default_Probability\")  # Prepare input for ML.\n",
    "\n",
    "# Display the prepared data to confirm the transformation\n",
    "data_prepared.show()  # Verify the transformed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d01d6084-f546-46e1-83e2-3d5da946fce8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Split the data into training and test sets\n",
    "# Use an 80-20 split for training and testing\n",
    "train_data, test_data = data_prepared.randomSplit([0.8, 0.2], seed=42)  # Create training and testing datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14baff4c-f0f8-40b6-b4c5-8fb20a032f4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Train the Linear Regression Model\n",
    "# Initialize the Linear Regression model\n",
    "#The features column contains vectors like [age, income, credit_score].\n",
    "#The Default_Probability column contains numerical values representing the probability that a person will default on a loan.\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Default_Probability\")  # Define the regression model.\n",
    "\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_model = lr.fit(train_data)  # Train the linear regression model.\n",
    "# The fit() method is used to train the machine learning model on the dataset provided\n",
    "# It processes the train_data DataFrame to find the best coefficients and intercept for the linear regression equation\n",
    "# It minimizes the cost function (e.g., Mean Squared Error) during training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad411670-c5b1-48b0-bc09-237dda6a733a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-0.006000376620951353,8.783689937575941e-07,1.4981374503054674e-06,-0.0031586697031177054,2.0604575901113477e-06]\nIntercept:  0.6645449830442633\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Output model coefficients and intercept\n",
    "# Display the coefficients (weights) and intercept (bias term) of the model\n",
    "print(\"Coefficients: \", lr_model.coefficients)  # Output feature weights.\n",
    "print(\"Intercept: \", lr_model.intercept)  # Output model bias.\n",
    " \n",
    "\n",
    "# The intercept is value of model if all feature are 0\n",
    "# To determine the most influential feature in your example, look at the absolute values of the coefficients, as these indicate the strength of the impact on the target variable. Larger absolute values imply a stronger effect.\n",
    "\n",
    "#Calculate Absolute Values of Coefficients\n",
    "\n",
    "# Now after calculating Absolute Values Ranking by Strength:\n",
    "# Feature 1: 0.006000 (Strongest influence)\n",
    "# Feature 4: 0.003158 (Second strongest influence)\n",
    "# Feature 5: 0.00000206\n",
    "# Feature 3: 0.00000149\n",
    "# Feature 2: 0.000000878 (Weakest influence)\n",
    "\n",
    "#Conclusion:\n",
    "#Feature 1 has the strongest influence on the target variable because it has the largest absolute coefficient (−0.006 , −0.006).\n",
    "#A unit change in Feature 1 leads to a 0.006 decrease in the predicted Default_Probability.\n",
    "#Feature 4 is the second most influential, but its impact is about half that of Feature 1.\n",
    "#Features 2, 3, and 5 have very small coefficients, indicating that they have minimal influence on the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64927f6e-4c86-4a48-b49d-5e22dbc99dfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n|            features| Default_Probability|         prediction|\n+--------------------+--------------------+-------------------+\n|[21.0,50080.0,356...|0.028782676313338973| 0.6142986284995059|\n|[22.0,53992.0,697...|  0.8647223762550532|  0.589754475654688|\n|[23.0,22976.0,473...|  0.5139894891598108| 0.6097333106783765|\n|[26.0,34827.0,416...|  0.6715731955927996| 0.5844243433954437|\n|[27.0,66318.0,474...| 0.17701048427674682| 0.6091467008215131|\n|[28.0,1854.0,2523...|0.039312139841098936| 0.5285721314603798|\n|[30.0,71592.0,258...|  0.8383287047111379| 0.5695401092584892|\n|[33.0,49925.0,398...|0.014544665667881929| 0.5312280391328901|\n|[37.0,24776.0,256...| 0.39654278232127016|  0.496276047095216|\n|[37.0,76450.0,187...|  0.8521815003185401| 0.5371657739428969|\n|[37.0,99098.0,431...| 0.07586332810866392| 0.5947788256929901|\n|[39.0,3693.0,1161...|   0.755137255673619| 0.4422328681550375|\n|[40.0,56820.0,119...|  0.5203077009037933|0.46457130696321625|\n|[41.0,83948.0,240...|  0.8129010091300776| 0.5283475083345051|\n|[43.0,63003.0,388...| 0.04086861626647886| 0.5151188280871544|\n|[45.0,43557.0,235...| 0.13401522845064073| 0.4649600507684424|\n|[48.0,74530.0,679...| 0.13882717264941014| 0.4500794494839745|\n+--------------------+--------------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Make predictions\n",
    "# Use the test data to make predictions\n",
    "predictions = lr_model.transform(test_data)  # Apply the model to the test dataset.\n",
    "\n",
    "# Display predictions alongside actual values\n",
    "predictions.select(\"features\", \"Default_Probability\", \"prediction\").show()  # Compare predictions with actuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "604f69b4-7691-454c-a232-3683afca884d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 0.35910683199481575\nR² (Coefficient of Determination): -0.18548115618368066\nLinear Regression Model Summary:\n  Coefficients: [-0.006000376620951353,8.783689937575941e-07,1.4981374503054674e-06,-0.0031586697031177054,2.0604575901113477e-06]\n  Intercept: 0.6645449830442633\n  RMSE: 0.35910683199481575\n  R²: -0.18548115618368066\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 7: Evaluate the model\n",
    "# Initialize a regression evaluator to calculate metrics\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"Default_Probability\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"  # Evaluate RMSE\n",
    ")  # Set up an evaluator for regression metrics.\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)  # Calculate RMSE.\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)  # Print the RMSE.\n",
    "\n",
    "# Calculate R-squared using the same evaluator\n",
    "r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})  # Calculate R².\n",
    "print(\"R² (Coefficient of Determination):\", r2)  # Print the R² value.\n",
    "\n",
    "# Conclusion\n",
    "# Display a summary of the model performance\n",
    "print(\"Linear Regression Model Summary:\")  # Begin summary.\n",
    "print(f\"  Coefficients: {lr_model.coefficients}\")  # Output coefficients.\n",
    "print(f\"  Intercept: {lr_model.intercept}\")  # Output intercept.\n",
    "print(f\"  RMSE: {rmse}\")  # Output RMSE.\n",
    "print(f\"  R²: {r2}\")  # Output R².\n",
    "\n",
    "#Root Mean Squared Error (RMSE): 0.35910683199481575\n",
    "#What it measures: The average magnitude of the error (difference between predicted and actual values), with larger errors weighted more heavily because they are squared.\n",
    "\n",
    "#Interpretation: A lower RMSE indicates better model performance. In this case, the RMSE is approximately 0.359, meaning the model's predictions deviate from the actual values by about 0.359 on average.\n",
    "#R² (Coefficient of Determination): -0.18548115618368066\n",
    "#What it measures: The proportion of variance in the dependent variable (target) explained by the independent variables (features).\n",
    "\n",
    "#Interpretation:\n",
    "#Values close to 1 indicate a good fit.\n",
    "#A negative R² value indicates that the model performs worse than a horizontal line (mean of the target values).\n",
    "#Here, an R² of -0.185 suggests the model is performing poorly and does not explain the variance in the target variable.\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "#Coefficients:\n",
    "#[-0.006000376620951353, 8.783689937575941e-07, 1.4981374503054674e-06, -0.0031586697031177054, 2.0604575901113477e-06]\n",
    "\n",
    "#What they represent: The weights applied to each feature in the linear regression equation.\n",
    "#Interpretation:\n",
    "#A positive coefficient indicates that as the feature increases, the target value increases.\n",
    "#A negative coefficient indicates that as the feature increases, the target value decreases.\n",
    "#In this case:\n",
    "#Feature 1: A small negative effect.\n",
    "#Feature 2 and 3: Very small positive effects (close to zero).\n",
    "#Feature 4: Small negative effect.\n",
    "#Feature 5: Small positive effect.\n",
    "\n",
    "#Intercept: 0.6645449830442633\n",
    "#What it represents: The predicted value of the target variable when all features are zero.\n",
    "#Interpretation: If all feature values are zero, the predicted target value is approximately 0.6645.\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f17f086-6fa0-4918-98f3-7f45967c373a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Summary ------}}}}}}}}}}}}}\n",
    "#This model is not performing well:\n",
    "\n",
    "# RMSE suggests the predictions are moderately far from actual values.\n",
    "# R² is negative, indicating the model explains less of the variance than a trivial model (predicting the mean).\n",
    "# Possible reasons for poor performance include:\n",
    "\n",
    "# The model may not be appropriate for the data (e.g., linear regression for non-linear relationships).\n",
    "# Features may not be sufficiently predictive of the target.\n",
    "# Data preprocessing issues (e.g., missing values, poor scaling).\n",
    "\n",
    "# Improving the model might involve:\n",
    "# Examining feature importance and correlations.\n",
    "# Trying different feature transformations or additional features.\n",
    "# Experimenting with more complex models."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "linear_regression_banking",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
